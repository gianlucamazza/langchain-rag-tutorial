# LangChain RAG - Guida Completa

Un progetto educativo completo per costruire un sistema **RAG (Retrieval-Augmented Generation)** utilizzando LangChain, con confronti tra diverse tecnologie e strategie.

## üìã Indice

- [Cos'√® RAG?](#cos√®-rag)
- [Caratteristiche](#caratteristiche)
- [Prerequisiti](#prerequisiti)
- [Installazione](#installazione)
- [Configurazione](#configurazione)
- [Utilizzo](#utilizzo)
- [Contenuto del Notebook](#contenuto-del-notebook)
- [Confronti Tecnologici](#confronti-tecnologici)
- [Troubleshooting](#troubleshooting)
- [Risorse](#risorse)

## ü§î Cos'√® RAG?

**RAG (Retrieval-Augmented Generation)** √® una tecnica potente che combina i punti di forza dei Large Language Models (LLM) con il recupero di informazioni da una base di conoscenza esterna.

### Funzionamento

```
Query Utente ‚Üí Embedding ‚Üí Vector Search ‚Üí Documenti Recuperati ‚Üí LLM ‚Üí Risposta
                 ‚Üì                           ‚Üì
          Vector Store ‚Üê Embeddings ‚Üê Chunks ‚Üê Documenti
```

RAG migliora le risposte degli LLM in tre passi:
1. **Recupero**: trova documenti rilevanti da una knowledge base
2. **Augmentation**: arricchisce il prompt con il contesto recuperato
3. **Generazione**: produce risposte informate basate su LLM + documenti

## ‚ú® Caratteristiche

- üìö **Caricamento documenti** da web, PDF, testi
- ‚úÇÔ∏è **Strategie di chunking** configurabili
- üîÑ **Confronto embeddings**: OpenAI vs HuggingFace
- üîç **Confronto retrieval**: Similarity Search vs MMR
- ü§ñ **Chain RAG complete** end-to-end
- üè∑Ô∏è **Metadata filtering** per ricerche avanzate
- üìä **Source attribution** per trasparenza
- üí° **Best practices** e pitfalls comuni

## üîß Prerequisiti

- **Python 3.8+** (testato con Python 3.14)
- **API Key OpenAI** (obbligatoria) - [Ottienila qui](https://platform.openai.com/api-keys)
- **API Key HuggingFace** (opzionale) - Per embeddings locali non serve
- **4GB+ RAM** - Per i modelli sentence-transformers

## üöÄ Installazione

### 1. Clona o scarica il progetto

```bash
cd /percorso/della/cartella
```

### 2. Crea un ambiente virtuale Python

```bash
# Crea l'ambiente virtuale
python3 -m venv venv

# Attiva l'ambiente virtuale
# Su macOS/Linux:
source venv/bin/activate

# Su Windows:
# venv\Scripts\activate
```

### 3. Installa le dipendenze

```bash
pip install -r requirements.txt
```

Questo installer√† tutte le librerie necessarie:
- **LangChain** e moduli correlati
- **OpenAI** client API
- **FAISS** per similarity search
- **Sentence Transformers** per embeddings locali
- **Jupyter** per eseguire il notebook

### 4. Verifica l'installazione

```bash
python -c "import langchain; import openai; import faiss; print('‚úì Installazione completata!')"
```

## ‚öôÔ∏è Configurazione

### 1. Configura le API Keys

Crea un file `.env` nella directory del progetto:

```bash
# Crea il file .env
touch .env
```

Aggiungi le tue chiavi API:

```env
# Obbligatorio - Ottieni da https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-...

# Opzionale - Solo se vuoi usare API HuggingFace (non necessario per embeddings locali)
HUGGINGFACE_API_KEY=hf_...
```

‚ö†Ô∏è **IMPORTANTE**: Non condividere mai il file `.env` o le tue API keys! Il file √® gi√† escluso da git tramite `.gitignore`.

### 2. Verifica la configurazione

Esegui il notebook e verifica la cella di test API key - vedrai:
```
‚úì API key is VALID! Connection successful.
```

## üìì Utilizzo

### Avvia Jupyter Notebook

```bash
# Assicurati che l'ambiente virtuale sia attivo
source venv/bin/activate

# Avvia Jupyter
jupyter notebook
```

Il browser si aprir√† automaticamente. Apri `langchain_rag_complete.ipynb` e segui il notebook cella per cella.

### Esecuzione Rapida

1. **Run All**: Kernel ‚Üí Restart & Run All
2. Attendi il completamento (2-5 minuti al primo avvio)
3. Esplora i risultati e sperimenta con le query

## üìö Contenuto del Notebook

Il notebook √® organizzato in sezioni progressive:

### 1. Setup e Installazione
- Installazione dipendenze
- Configurazione API keys
- Test connessione OpenAI

### 2. Document Loading
- WebBaseLoader per documentazione online
- Metadata personalizzati
- Gestione multi-source

### 3. Text Splitting
- RecursiveCharacterTextSplitter
- Confronto strategie (1000/200 vs 500/100)
- Best practices per chunk size

### 4. Embeddings
**Confronto completo OpenAI vs HuggingFace:**
- Dimensioni vettori (1536 vs 384)
- Performance (tempo, qualit√†)
- Costi e privacy

### 5. Vector Stores
- Creazione FAISS vector stores
- Indexing e similarity search
- Testing con entrambi gli embeddings

### 6. Retrieval Strategies
**Confronto Similarity vs MMR:**
- Similarity: massima rilevanza
- MMR: bilanciamento rilevanza/diversit√†
- Parametri e configurazione

### 7. RAG Chains
- Costruzione chain completa
- LLM initialization (GPT-4o-mini)
- Prompt engineering
- Document combination

### 8. Evaluation
- Test query multiple
- Confronto risultati tra strategie
- Source attribution

### 9. Advanced Features
- Metadata filtering
- Custom retrievers
- Production tips

### 10. Best Practices
- Common pitfalls da evitare
- Performance optimization
- Security considerations

## üîÑ Confronti Tecnologici

### OpenAI vs HuggingFace Embeddings

| Caratteristica | OpenAI | HuggingFace |
|----------------|--------|-------------|
| **Qualit√†** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Eccellente | ‚≠ê‚≠ê‚≠ê‚≠ê Molto buona |
| **Costo** | üí∞ Pay-per-use | üÜì Gratis |
| **Velocit√†** | ‚ö° Veloce (API) | üê¢ Pi√π lento (locale) |
| **Privacy** | ‚òÅÔ∏è Dati su cloud | üîí Dati locali |
| **Dimensione** | 1536d | 384d |
| **Setup** | API key | Download modello |

**Raccomandazione:**
- **Produzione/Qualit√†**: OpenAI
- **Sviluppo/Privacy**: HuggingFace

### Similarity Search vs MMR

| Caratteristica | Similarity | MMR |
|----------------|------------|-----|
| **Rilevanza** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Massima | ‚≠ê‚≠ê‚≠ê‚≠ê Alta |
| **Diversit√†** | ‚≠ê‚≠ê Bassa | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Alta |
| **Velocit√†** | ‚ö° Veloce | üê¢ Pi√π lento |
| **Ridondanza** | üìù Possibile | ‚úÖ Minimizzata |
| **Use case** | Query specifiche | Esplorazione topic |

**Raccomandazione:**
- **Query precise**: Similarity
- **Overview/Diversit√†**: MMR

## üêõ Troubleshooting

### Errore: "API key is INVALID"

```bash
# Verifica che la chiave sia corretta nel file .env
cat .env | grep OPENAI_API_KEY

# Ricarica il kernel Jupyter dopo aver modificato .env
# Kernel ‚Üí Restart
```

### Errore: "ipykernel not found"

```bash
pip install ipykernel
python -m ipykernel install --user --name=venv
```

### ModuleNotFoundError

```bash
# Reinstalla le dipendenze
pip install -r requirements.txt --upgrade
```

### Download lento HuggingFace models

Il primo download del modello `sentence-transformers/all-MiniLM-L6-v2` pu√≤ richiedere 1-2 minuti. √à normale e avviene solo la prima volta.

### FAISS import error

```bash
# Su Mac con Apple Silicon, potrebbe servire:
pip uninstall faiss-cpu
pip install faiss-cpu --no-cache-dir
```

### Memory errors

Se hai meno di 4GB RAM disponibili:
- Riduci `chunk_size` a 500
- Usa meno documenti in `urls`
- Riduci `k` nei retriever a 2-3

## üìñ Risorse

### Documentazione Ufficiale
- [LangChain Docs](https://python.langchain.com/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [FAISS GitHub](https://github.com/facebookresearch/faiss)
- [Sentence Transformers](https://www.sbert.net/)

### Tutorial e Guide
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [RAG Best Practices](https://python.langchain.com/docs/use_cases/question_answering/sources)

### Paper e Research
- [RAG Paper (Lewis et al.)](https://arxiv.org/abs/2005.11401)
- [Sentence-BERT](https://arxiv.org/abs/1908.10084)

## ü§ù Contributi

Suggerimenti per migliorare questo progetto:
1. Testare con diversi tipi di documenti (PDF, CSV, etc.)
2. Aggiungere metriche di valutazione automatiche
3. Implementare conversational memory
4. Confrontare altri modelli di embeddings
5. Ottimizzare per dataset pi√π grandi

## üìù Licenza

Progetto educativo - libero utilizzo per scopi di apprendimento.

## üôè Ringraziamenti

- **LangChain** per il framework eccellente
- **OpenAI** per GPT e embeddings API
- **HuggingFace** per modelli open source
- **FAISS** per similarity search efficiente

---

**Buon apprendimento! üöÄ**

Per domande o problemi, consulta la sezione [Troubleshooting](#troubleshooting) o la documentazione ufficiale.
