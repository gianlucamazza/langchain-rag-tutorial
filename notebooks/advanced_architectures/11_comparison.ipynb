{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 - Architecture Comparison & Benchmark\n",
    "\n",
    "This notebook provides a comprehensive comparison of all 8 RAG architectures implemented in this tutorial.\n",
    "\n",
    "**Architectures Compared:**\n",
    "1. Simple RAG\n",
    "2. RAG with Memory\n",
    "3. Branched RAG\n",
    "4. HyDe\n",
    "5. Adaptive RAG\n",
    "6. Corrective RAG (CRAG)\n",
    "7. Self-RAG\n",
    "8. Agentic RAG\n",
    "\n",
    "**Metrics Evaluated:**\n",
    "- Latency (response time)\n",
    "- Complexity (implementation)\n",
    "- Use case fit\n",
    "- Trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianlucamazza/Workspace/notebooks/llm_rag/venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RAG ARCHITECTURES COMPARISON\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from shared.utils import print_section_header, print_comparison_table\n",
    "\n",
    "print_section_header(\"RAG Architectures Comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Complexity & Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPLEXITY & PERFORMANCE\n",
      "================================================================================\n",
      "\n",
      "Architecture  Complexity  Latency   Cost       Accuracy   \n",
      "----------------------------------------------------------\n",
      "Simple RAG    ‚≠ê           ~2s       Low        Good       \n",
      "Memory RAG    ‚≠ê‚≠ê          ~2-3s     Low-Med    Good       \n",
      "Branched RAG  ‚≠ê‚≠ê‚≠ê         ~5-8s     Medium     Very Good  \n",
      "HyDe          ‚≠ê‚≠ê‚≠ê         ~4-6s     Medium     Very Good  \n",
      "Adaptive RAG  ‚≠ê‚≠ê‚≠ê‚≠ê        Variable  Optimized  Very Good  \n",
      "CRAG          ‚≠ê‚≠ê‚≠ê‚≠ê        ~10-15s   High       Excellent  \n",
      "Self-RAG      ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê       ~10-20s   High       Excellent  \n",
      "Agentic RAG   ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê       ~20-40s   Very High  Excellent  \n",
      "\n",
      "üí° Key Insights:\n",
      "   - Complexity ‚Üë = Latency ‚Üë + Cost ‚Üë\n",
      "   - Simple architectures: Fast, cheap, good quality\n",
      "   - Advanced architectures: Slow, expensive, excellent quality\n",
      "   - Choose based on requirements and constraints\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Complexity & Performance\")\n",
    "\n",
    "data = [\n",
    "    [\"Architecture\", \"Complexity\", \"Latency\", \"Cost\", \"Accuracy\"],\n",
    "    [\"Simple RAG\", \"‚≠ê\", \"~2s\", \"Low\", \"Good\"],\n",
    "    [\"Memory RAG\", \"‚≠ê‚≠ê\", \"~2-3s\", \"Low-Med\", \"Good\"],\n",
    "    [\"Branched RAG\", \"‚≠ê‚≠ê‚≠ê\", \"~5-8s\", \"Medium\", \"Very Good\"],\n",
    "    [\"HyDe\", \"‚≠ê‚≠ê‚≠ê\", \"~4-6s\", \"Medium\", \"Very Good\"],\n",
    "    [\"Adaptive RAG\", \"‚≠ê‚≠ê‚≠ê‚≠ê\", \"Variable\", \"Optimized\", \"Very Good\"],\n",
    "    [\"CRAG\", \"‚≠ê‚≠ê‚≠ê‚≠ê\", \"~10-15s\", \"High\", \"Excellent\"],\n",
    "    [\"Self-RAG\", \"‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\", \"~10-20s\", \"High\", \"Excellent\"],\n",
    "    [\"Agentic RAG\", \"‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\", \"~20-40s\", \"Very High\", \"Excellent\"],\n",
    "]\n",
    "\n",
    "print_comparison_table(data)\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   - Complexity ‚Üë = Latency ‚Üë + Cost ‚Üë\")\n",
    "print(\"   - Simple architectures: Fast, cheap, good quality\")\n",
    "print(\"   - Advanced architectures: Slow, expensive, excellent quality\")\n",
    "print(\"   - Choose based on requirements and constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Case Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "USE CASE RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "Use Case           Recommended Architecture  Why                       \n",
      "-----------------------------------------------------------------------\n",
      "General Q&A        Simple RAG                Fast, cheap, good enough  \n",
      "Chatbot            Memory RAG                Handles follow-ups        \n",
      "Research           Branched RAG              Comprehensive coverage    \n",
      "Ambiguous queries  HyDe                      Better semantic matching  \n",
      "Mixed workload     Adaptive RAG              Balances cost/quality     \n",
      "High-accuracy      CRAG                      Quality checking + web    \n",
      "Self-correcting    Self-RAG                  Autonomous refinement     \n",
      "Complex reasoning  Agentic RAG               Multi-step + tools        \n",
      "\n",
      "üìå Selection Guide:\n",
      "   1. Start with Simple RAG\n",
      "   2. Add Memory if conversational\n",
      "   3. Use Adaptive for mixed workloads\n",
      "   4. Use CRAG/Self-RAG for high-stakes\n",
      "   5. Use Agentic for complex multi-step tasks\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Use Case Recommendations\")\n",
    "\n",
    "use_cases = [\n",
    "    [\"Use Case\", \"Recommended Architecture\", \"Why\"],\n",
    "    [\"General Q&A\", \"Simple RAG\", \"Fast, cheap, good enough\"],\n",
    "    [\"Chatbot\", \"Memory RAG\", \"Handles follow-ups\"],\n",
    "    [\"Research\", \"Branched RAG\", \"Comprehensive coverage\"],\n",
    "    [\"Ambiguous queries\", \"HyDe\", \"Better semantic matching\"],\n",
    "    [\"Mixed workload\", \"Adaptive RAG\", \"Balances cost/quality\"],\n",
    "    [\"High-accuracy\", \"CRAG\", \"Quality checking + web\"],\n",
    "    [\"Self-correcting\", \"Self-RAG\", \"Autonomous refinement\"],\n",
    "    [\"Complex reasoning\", \"Agentic RAG\", \"Multi-step + tools\"],\n",
    "]\n",
    "\n",
    "print_comparison_table(use_cases)\n",
    "\n",
    "print(\"\\nüìå Selection Guide:\")\n",
    "print(\"   1. Start with Simple RAG\")\n",
    "print(\"   2. Add Memory if conversational\")\n",
    "print(\"   3. Use Adaptive for mixed workloads\")\n",
    "print(\"   4. Use CRAG/Self-RAG for high-stakes\")\n",
    "print(\"   5. Use Agentic for complex multi-step tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE MATRIX\n",
      "================================================================================\n",
      "\n",
      "Feature        Simple  Memory  Branch  HyDe  Adapt  CRAG  Self  Agent  \n",
      "-----------------------------------------------------------------------\n",
      "Conversation   ‚úó       ‚úì       ‚úó       ‚úó     ‚úó      ‚úó     ‚úó     ‚úì      \n",
      "Multi-query    ‚úó       ‚úó       ‚úì       ‚úó     ‚úó      ‚úó     ‚úó     ‚úó      \n",
      "Semantic+      ‚úó       ‚úó       ‚úó       ‚úì     ‚úì      ‚úó     ‚úó     ‚úó      \n",
      "Routing        ‚úó       ‚úó       ‚úó       ‚úó     ‚úì      ‚úó     ‚úó     ‚úó      \n",
      "Web search     ‚úó       ‚úó       ‚úó       ‚úó     ‚úó      ‚úì     ‚úó     ‚úì      \n",
      "Self-critique  ‚úó       ‚úó       ‚úó       ‚úó     ‚úó      ‚úó     ‚úì     ‚úó      \n",
      "Multi-tool     ‚úó       ‚úó       ‚úó       ‚úó     ‚úó      ‚úó     ‚úó     ‚úì      \n",
      "\n",
      "‚úì = Supported | ‚úó = Not supported\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Feature Matrix\")\n",
    "\n",
    "features = [\n",
    "    [\"Feature\", \"Simple\", \"Memory\", \"Branch\", \"HyDe\", \"Adapt\", \"CRAG\", \"Self\", \"Agent\"],\n",
    "    [\"Conversation\", \"‚úó\", \"‚úì\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\"],\n",
    "    [\"Multi-query\", \"‚úó\", \"‚úó\", \"‚úì\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\"],\n",
    "    [\"Semantic+\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\", \"‚úì\", \"‚úó\", \"‚úó\", \"‚úó\"],\n",
    "    [\"Routing\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\", \"‚úó\", \"‚úó\", \"‚úó\"],\n",
    "    [\"Web search\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\", \"‚úó\", \"‚úì\"],\n",
    "    [\"Self-critique\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\", \"‚úó\"],\n",
    "    [\"Multi-tool\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úó\", \"‚úì\"],\n",
    "]\n",
    "\n",
    "print_comparison_table(features)\n",
    "\n",
    "print(\"\\n‚úì = Supported | ‚úó = Not supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trade-offs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRADE-OFFS\n",
      "================================================================================\n",
      "\n",
      "**Simple RAG**\n",
      "  ‚úÖ Pros: Fast, cheap, easy to implement\n",
      "  ‚ùå Cons: Limited features, no conversation memory\n",
      "\n",
      "**Memory RAG**\n",
      "  ‚úÖ Pros: Conversational, natural follow-ups\n",
      "  ‚ùå Cons: Higher cost (context), privacy concerns\n",
      "\n",
      "**Branched RAG**\n",
      "  ‚úÖ Pros: Comprehensive coverage, diverse results\n",
      "  ‚ùå Cons: Slower, more API calls\n",
      "\n",
      "**HyDe**\n",
      "  ‚úÖ Pros: Better semantic matching, handles jargon\n",
      "  ‚ùå Cons: Extra LLM call, may hallucinate\n",
      "\n",
      "**Adaptive RAG**\n",
      "  ‚úÖ Pros: Optimized cost/quality, scalable\n",
      "  ‚ùå Cons: Complex routing, needs tuning\n",
      "\n",
      "**CRAG**\n",
      "  ‚úÖ Pros: High accuracy, robust, web fallback\n",
      "  ‚ùå Cons: Very slow, expensive\n",
      "\n",
      "**Self-RAG**\n",
      "  ‚úÖ Pros: Self-correcting, high quality\n",
      "  ‚ùå Cons: Very slow, very expensive\n",
      "\n",
      "**Agentic RAG**\n",
      "  ‚úÖ Pros: Autonomous, multi-step, extensible\n",
      "  ‚ùå Cons: Slowest, most expensive, unpredictable\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Trade-offs\")\n",
    "\n",
    "print(\"**Simple RAG**\")\n",
    "print(\"  ‚úÖ Pros: Fast, cheap, easy to implement\")\n",
    "print(\"  ‚ùå Cons: Limited features, no conversation memory\\n\")\n",
    "\n",
    "print(\"**Memory RAG**\")\n",
    "print(\"  ‚úÖ Pros: Conversational, natural follow-ups\")\n",
    "print(\"  ‚ùå Cons: Higher cost (context), privacy concerns\\n\")\n",
    "\n",
    "print(\"**Branched RAG**\")\n",
    "print(\"  ‚úÖ Pros: Comprehensive coverage, diverse results\")\n",
    "print(\"  ‚ùå Cons: Slower, more API calls\\n\")\n",
    "\n",
    "print(\"**HyDe**\")\n",
    "print(\"  ‚úÖ Pros: Better semantic matching, handles jargon\")\n",
    "print(\"  ‚ùå Cons: Extra LLM call, may hallucinate\\n\")\n",
    "\n",
    "print(\"**Adaptive RAG**\")\n",
    "print(\"  ‚úÖ Pros: Optimized cost/quality, scalable\")\n",
    "print(\"  ‚ùå Cons: Complex routing, needs tuning\\n\")\n",
    "\n",
    "print(\"**CRAG**\")\n",
    "print(\"  ‚úÖ Pros: High accuracy, robust, web fallback\")\n",
    "print(\"  ‚ùå Cons: Very slow, expensive\\n\")\n",
    "\n",
    "print(\"**Self-RAG**\")\n",
    "print(\"  ‚úÖ Pros: Self-correcting, high quality\")\n",
    "print(\"  ‚ùå Cons: Very slow, very expensive\\n\")\n",
    "\n",
    "print(\"**Agentic RAG**\")\n",
    "print(\"  ‚úÖ Pros: Autonomous, multi-step, extensible\")\n",
    "print(\"  ‚ùå Cons: Slowest, most expensive, unpredictable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DECISION FRAMEWORK\n",
      "================================================================================\n",
      "\n",
      "**Step 1: Define Requirements**\n",
      "\n",
      "Ask yourself:\n",
      "  - What's the latency requirement? (<2s, <5s, <10s, >10s)\n",
      "  - What's the budget? (low, medium, high)\n",
      "  - What's the accuracy requirement? (good, very good, excellent)\n",
      "  - Is conversation needed? (yes/no)\n",
      "  - Are queries simple or complex? (simple, mixed, complex)\n",
      "\n",
      "**Step 2: Apply Decision Tree**\n",
      "\n",
      "```\n",
      "If latency < 2s AND budget low:\n",
      "  ‚Üí Simple RAG\n",
      "\n",
      "If conversational:\n",
      "  ‚Üí Memory RAG\n",
      "\n",
      "If queries are complex AND budget medium:\n",
      "  ‚Üí Branched RAG or HyDe\n",
      "\n",
      "If workload is mixed:\n",
      "  ‚Üí Adaptive RAG\n",
      "\n",
      "If accuracy is critical AND budget high:\n",
      "  ‚Üí CRAG or Self-RAG\n",
      "\n",
      "If multi-step reasoning needed:\n",
      "  ‚Üí Agentic RAG\n",
      "```\n",
      "\n",
      "**Step 3: Start Simple, Iterate**\n",
      "\n",
      "  1. Start with Simple RAG\n",
      "  2. Measure performance and quality\n",
      "  3. Identify gaps (speed? accuracy? features?)\n",
      "  4. Upgrade to appropriate architecture\n",
      "  5. Monitor and iterate\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Decision Framework\")\n",
    "\n",
    "print(\"**Step 1: Define Requirements**\\n\")\n",
    "print(\"Ask yourself:\")\n",
    "print(\"  - What's the latency requirement? (<2s, <5s, <10s, >10s)\")\n",
    "print(\"  - What's the budget? (low, medium, high)\")\n",
    "print(\"  - What's the accuracy requirement? (good, very good, excellent)\")\n",
    "print(\"  - Is conversation needed? (yes/no)\")\n",
    "print(\"  - Are queries simple or complex? (simple, mixed, complex)\")\n",
    "\n",
    "print(\"\\n**Step 2: Apply Decision Tree**\\n\")\n",
    "print(\"```\")\n",
    "print(\"If latency < 2s AND budget low:\")\n",
    "print(\"  ‚Üí Simple RAG\")\n",
    "print(\"\")\n",
    "print(\"If conversational:\")\n",
    "print(\"  ‚Üí Memory RAG\")\n",
    "print(\"\")\n",
    "print(\"If queries are complex AND budget medium:\")\n",
    "print(\"  ‚Üí Branched RAG or HyDe\")\n",
    "print(\"\")\n",
    "print(\"If workload is mixed:\")\n",
    "print(\"  ‚Üí Adaptive RAG\")\n",
    "print(\"\")\n",
    "print(\"If accuracy is critical AND budget high:\")\n",
    "print(\"  ‚Üí CRAG or Self-RAG\")\n",
    "print(\"\")\n",
    "print(\"If multi-step reasoning needed:\")\n",
    "print(\"  ‚Üí Agentic RAG\")\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\n**Step 3: Start Simple, Iterate**\\n\")\n",
    "print(\"  1. Start with Simple RAG\")\n",
    "print(\"  2. Measure performance and quality\")\n",
    "print(\"  3. Identify gaps (speed? accuracy? features?)\")\n",
    "print(\"  4. Upgrade to appropriate architecture\")\n",
    "print(\"  5. Monitor and iterate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Quick Reference Guide\n",
    "\n",
    "| Scenario | Architecture | Priority |\n",
    "|----------|--------------|----------|\n",
    "| **Starting out** | Simple RAG | ‚úÖ‚úÖ‚úÖ |\n",
    "| **Need speed** | Simple RAG | ‚úÖ‚úÖ‚úÖ |\n",
    "| **Limited budget** | Simple RAG, HuggingFace | ‚úÖ‚úÖ‚úÖ |\n",
    "| **Chatbot** | Memory RAG | ‚úÖ‚úÖ |\n",
    "| **Research tool** | Branched RAG | ‚úÖ‚úÖ |\n",
    "| **Ambiguous queries** | HyDe | ‚úÖ‚úÖ |\n",
    "| **Mixed workload** | Adaptive RAG | ‚úÖ‚úÖ |\n",
    "| **High accuracy** | CRAG, Self-RAG | ‚úÖ |\n",
    "| **Complex reasoning** | Agentic RAG | ‚úÖ |\n",
    "\n",
    "### Final Recommendations\n",
    "\n",
    "1. **Production systems**: Start with Simple or Memory RAG\n",
    "2. **Cost-sensitive**: Use Adaptive RAG to optimize\n",
    "3. **Quality-critical**: Use CRAG or Self-RAG\n",
    "4. **Complex tasks**: Use Agentic RAG\n",
    "\n",
    "5. **Always**:\n",
    "   - Monitor performance and costs\n",
    "   - A/B test architectures\n",
    "   - Iterate based on real usage\n",
    "   - Keep infrastructure simple\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Review individual architecture notebooks for implementation details\n",
    "- Test with your specific use case\n",
    "- Measure metrics that matter to you\n",
    "- Deploy and monitor in production\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've completed the LangChain RAG Tutorial and explored 8 different RAG architectures!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
