{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. RAG Evaluation with RAGAS Framework\n",
    "\n",
    "**Complexity:** ⭐⭐⭐⭐\n",
    "\n",
    "## Overview\n",
    "\n",
    "**RAGAS** (RAG Assessment) is a comprehensive framework for evaluating Retrieval-Augmented Generation systems. It provides metrics to measure both retrieval quality and generation quality.\n",
    "\n",
    "### Why Evaluation Matters\n",
    "\n",
    "Without evaluation, you can't:\n",
    "- ❌ Compare different RAG architectures objectively\n",
    "- ❌ Track improvements over time\n",
    "- ❌ Identify weak points in your system\n",
    "- ❌ Justify architectural choices\n",
    "- ❌ Optimize for production\n",
    "\n",
    "### RAGAS Metrics\n",
    "\n",
    "RAGAS provides 6 key metrics:\n",
    "\n",
    "1. **Faithfulness** (0-1): Is the answer grounded in retrieved context?\n",
    "   - Measures hallucination\n",
    "   - Higher = less hallucination\n",
    "\n",
    "2. **Answer Relevancy** (0-1): Is the answer relevant to the question?\n",
    "   - Measures if answer addresses the query\n",
    "   - Higher = more relevant\n",
    "\n",
    "3. **Context Precision** (0-1): Are retrieved documents relevant?\n",
    "   - Measures retrieval precision\n",
    "   - Higher = less noise\n",
    "\n",
    "4. **Context Recall** (0-1): Did retrieval find all relevant info?\n",
    "   - Measures retrieval completeness\n",
    "   - Requires ground truth\n",
    "\n",
    "5. **Answer Semantic Similarity** (0-1): Similarity to reference answer\n",
    "   - Measures correctness\n",
    "   - Requires ground truth answer\n",
    "\n",
    "6. **Answer Correctness** (0-1): Factual accuracy vs ground truth\n",
    "   - Weighted F1 score\n",
    "   - Requires ground truth\n",
    "\n",
    "### Evaluation Dataset\n",
    "\n",
    "For each test case, you need:\n",
    "```python\n",
    "{\n",
    "    \"question\": \"What is LCEL?\",\n",
    "    \"answer\": \"<generated answer>\",\n",
    "    \"contexts\": [\"<retrieved doc 1>\", \"<retrieved doc 2>\", ...],\n",
    "    \"ground_truth\": \"LCEL is LangChain Expression Language...\"  # optional\n",
    "}\n",
    "```\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "We'll evaluate all 12 RAG architectures:\n",
    "1. Simple RAG\n",
    "2. RAG with Memory\n",
    "3. Multi-Query RAG\n",
    "4. HyDE\n",
    "5. Adaptive RAG\n",
    "6. Corrective RAG\n",
    "7. Self-RAG\n",
    "8. Agentic RAG\n",
    "9. **Contextual RAG** [NEW]\n",
    "10. **Fusion RAG** [NEW]\n",
    "11. **SQL RAG** [NEW]\n",
    "12. **GraphRAG** [NEW]\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API Key: LOADED\n",
      "  Preview: sk-proj...vIQA\n",
      "✓ All imports successful\n",
      "✓ Using model: gpt-4o-mini\n",
      "✓ RAGAS available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path(\"../..\").resolve()))\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAGAS imports\n",
    "try:\n",
    "    from ragas import evaluate\n",
    "    from ragas.metrics import (\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    )\n",
    "    from datasets import Dataset\n",
    "    RAGAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️  RAGAS not installed. Install with: pip install ragas datasets\")\n",
    "    RAGAS_AVAILABLE = False\n",
    "\n",
    "from shared.config import (\n",
    "    verify_api_key,\n",
    "    DEFAULT_MODEL,\n",
    "    DEFAULT_TEMPERATURE,\n",
    "    OPENAI_EMBEDDING_MODEL,\n",
    "    VECTOR_STORE_DIR,\n",
    ")\n",
    "from shared.loaders import load_and_split\n",
    "from shared.prompts import RAG_PROMPT_TEMPLATE\n",
    "from shared.utils import (\n",
    "    format_docs,\n",
    "    print_section_header,\n",
    "    load_vector_store,\n",
    ")\n",
    "\n",
    "# Verify API key\n",
    "verify_api_key()\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"✓ Using model: {DEFAULT_MODEL}\")\n",
    "print(f\"✓ RAGAS available: {RAGAS_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Evaluation Dataset\n",
    "\n",
    "We'll create a test set with questions and ground truth answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING EVALUATION DATASET\n",
      "================================================================================\n",
      "\n",
      "\n",
      "✓ Created evaluation dataset with 5 questions\n",
      "\n",
      "Categories:\n",
      "  • [simple] What is LCEL in LangChain?...\n",
      "  • [multi-step] How do I build a RAG application?...\n",
      "  • [multi-concept] What are the different types of memory in LangChain?...\n",
      "  • [conceptual] How do retrievers work in RAG?...\n",
      "  • [comparison] What is the difference between chains and agents?...\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Creating Evaluation Dataset\")\n",
    "\n",
    "# Test questions with ground truth answers\n",
    "evaluation_dataset = [\n",
    "    {\n",
    "        \"question\": \"What is LCEL in LangChain?\",\n",
    "        \"ground_truth\": \"LCEL (LangChain Expression Language) is a declarative way to compose chains in LangChain. It uses the pipe operator (|) to chain components together and supports features like streaming, async execution, and parallel processing.\",\n",
    "        \"category\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I build a RAG application?\",\n",
    "        \"ground_truth\": \"To build a RAG application: 1) Load and split documents, 2) Create embeddings and vector store, 3) Set up a retriever, 4) Create a prompt template, 5) Chain retriever with LLM using LCEL, 6) Invoke the chain with queries.\",\n",
    "        \"category\": \"multi-step\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the different types of memory in LangChain?\",\n",
    "        \"ground_truth\": \"LangChain provides several memory types: ConversationBufferMemory (stores all messages), ConversationSummaryMemory (summarizes history), ConversationBufferWindowMemory (keeps last N messages), and ConversationKGMemory (knowledge graph-based).\",\n",
    "        \"category\": \"multi-concept\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do retrievers work in RAG?\",\n",
    "        \"ground_truth\": \"Retrievers fetch relevant documents from a vector store based on semantic similarity. They take a query, convert it to embeddings, search the vector store, and return top-k most similar documents. Common types include similarity search, MMR, and multi-query retrievers.\",\n",
    "        \"category\": \"conceptual\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the difference between chains and agents?\",\n",
    "        \"ground_truth\": \"Chains follow a predetermined sequence of steps, while agents can dynamically decide which tools to use and in what order based on the task. Agents have reasoning capabilities and can adapt their behavior, whereas chains are static workflows.\",\n",
    "        \"category\": \"comparison\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ Created evaluation dataset with {len(evaluation_dataset)} questions\")\n",
    "print(\"\\nCategories:\")\n",
    "for item in evaluation_dataset:\n",
    "    print(f\"  • [{item['category']}] {item['question'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SETTING UP RAG SYSTEM\n",
      "================================================================================\n",
      "\n",
      "Loading 4 documents from web...\n",
      "  - https://python.langchain.com/docs/use_cases/question_answering/\n",
      "  - https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
      "  - https://python.langchain.com/docs/modules/model_io/llms/\n",
      "  - https://python.langchain.com/docs/use_cases/chatbots/\n",
      "✓ Loaded 4 documents\n",
      "✓ Added custom metadata to all documents\n",
      "Splitting documents...\n",
      "  - Chunk size: 1000\n",
      "  - Chunk overlap: 200\n",
      "✓ Created 122 chunks\n",
      "\n",
      "  Sample chunk:\n",
      "    - Length: 991 chars\n",
      "    - Source: https://python.langchain.com/docs/use_cases/question_answering/\n",
      "    - Preview: Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Rea...\n",
      "\n",
      "✓ Loaded 122 chunks\n",
      "✓ Loaded vector store from /Users/gianlucamazza/Workspace/notebooks/llm_rag/data/vector_stores/ragas_evaluation\n",
      "✓ Loaded existing vector store\n",
      "✓ RAG system ready\n",
      "✓ Loaded 4 documents\n",
      "✓ Added custom metadata to all documents\n",
      "Splitting documents...\n",
      "  - Chunk size: 1000\n",
      "  - Chunk overlap: 200\n",
      "✓ Created 122 chunks\n",
      "\n",
      "  Sample chunk:\n",
      "    - Length: 991 chars\n",
      "    - Source: https://python.langchain.com/docs/use_cases/question_answering/\n",
      "    - Preview: Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Rea...\n",
      "\n",
      "✓ Loaded 122 chunks\n",
      "✓ Loaded vector store from /Users/gianlucamazza/Workspace/notebooks/llm_rag/data/vector_stores/ragas_evaluation\n",
      "✓ Loaded existing vector store\n",
      "✓ RAG system ready\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Setting Up RAG System\")\n",
    "\n",
    "# Load documents (returns tuple: original_docs, chunks)\n",
    "_, docs = load_and_split(chunk_size=1000, chunk_overlap=200)\n",
    "print(f\"\\n✓ Loaded {len(docs)} chunks\")\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=OPENAI_EMBEDDING_MODEL)\n",
    "store_path = VECTOR_STORE_DIR / \"ragas_evaluation\"\n",
    "\n",
    "vectorstore = load_vector_store(store_path, embeddings)\n",
    "if vectorstore is None:\n",
    "    print(\"\\nCreating vector store...\")\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    from shared.utils import save_vector_store\n",
    "    save_vector_store(vectorstore, store_path)\n",
    "    print(\"✓ Vector store created\")\n",
    "else:\n",
    "    print(\"✓ Loaded existing vector store\")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=DEFAULT_MODEL, temperature=DEFAULT_TEMPERATURE)\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "    | RAG_PROMPT_TEMPLATE\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✓ RAG system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Answers and Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING ANSWERS FOR EVALUATION\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Generating answers...\n",
      "\n",
      "[1/5] What is LCEL in LangChain?...\n",
      "  ✓ Answer: The context provided does not contain any information about \"LCEL\" in LangChain....\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[2/5] How do I build a RAG application?...\n",
      "  ✓ Answer: The context provided does not contain any information about \"LCEL\" in LangChain....\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[2/5] How do I build a RAG application?...\n",
      "  ✓ Answer: The context provided does not contain specific step-by-step instructions on how ...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[3/5] What are the different types of memory in LangChain?...\n",
      "  ✓ Answer: The context provided does not contain specific step-by-step instructions on how ...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[3/5] What are the different types of memory in LangChain?...\n",
      "  ✓ Answer: The different types of memory in LangChain mentioned in the context are:\n",
      "\n",
      "1. **S...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[4/5] How do retrievers work in RAG?...\n",
      "  ✓ Answer: The different types of memory in LangChain mentioned in the context are:\n",
      "\n",
      "1. **S...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[4/5] How do retrievers work in RAG?...\n",
      "  ✓ Answer: Retrievers in RAG (Retrieval-Augmented Generation) work by taking a user input a...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[5/5] What is the difference between chains and agents?...\n",
      "  ✓ Answer: Retrievers in RAG (Retrieval-Augmented Generation) work by taking a user input a...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "[5/5] What is the difference between chains and agents?...\n",
      "  ✓ Answer: The context provided does not contain specific information about the differences...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "✓ All answers generated\n",
      "  ✓ Answer: The context provided does not contain specific information about the differences...\n",
      "  ✓ Retrieved 4 contexts\n",
      "\n",
      "✓ All answers generated\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Generating Answers for Evaluation\")\n",
    "\n",
    "# Collect data for RAGAS evaluation\n",
    "ragas_data = {\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"contexts\": [],\n",
    "    \"ground_truth\": [],\n",
    "}\n",
    "\n",
    "print(\"\\nGenerating answers...\\n\")\n",
    "\n",
    "for i, item in enumerate(evaluation_dataset, 1):\n",
    "    question = item[\"question\"]\n",
    "    ground_truth = item[\"ground_truth\"]\n",
    "    \n",
    "    print(f\"[{i}/{len(evaluation_dataset)}] {question[:60]}...\")\n",
    "    \n",
    "    # Retrieve contexts\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    contexts = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # Generate answer\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    # Store\n",
    "    ragas_data[\"question\"].append(question)\n",
    "    ragas_data[\"answer\"].append(answer)\n",
    "    ragas_data[\"contexts\"].append(contexts)\n",
    "    ragas_data[\"ground_truth\"].append(ground_truth)\n",
    "    \n",
    "    print(f\"  ✓ Answer: {answer[:80]}...\")\n",
    "    print(f\"  ✓ Retrieved {len(contexts)} contexts\\n\")\n",
    "\n",
    "print(\"✓ All answers generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run RAGAS Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING RAGAS EVALUATION\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Evaluating with RAGAS metrics...\n",
      "(This may take a few minutes)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4781302cf548439b546c6e9f77a337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RAGAS EVALUATION RESULTS:\n",
      "================================================================================\n",
      "\n",
      "Overall Scores:\n",
      "  • faithfulness: 0.8836\n",
      "  • answer_relevancy: 0.3405\n",
      "  • context_precision: 0.3833\n",
      "  • context_recall: 0.2667\n",
      "\n",
      "================================================================================\n",
      "Per-Question Scores:\n",
      "================================================================================\n",
      "                                               question  faithfulness  answer_relevancy  context_precision  context_recall\n",
      "                          What is LCEL in LangChain?...      1.000000          0.000000           0.000000        0.000000\n",
      "                   How do I build a RAG application?...      1.000000          0.000000           1.000000        0.000000\n",
      "What are the different types of memory in LangChain?...      0.600000          1.000000           0.000000        0.000000\n",
      "                      How do retrievers work in RAG?...      0.818182          0.702429           0.416667        0.333333\n",
      "   What is the difference between chains and agents?...      1.000000          0.000000           0.500000        1.000000\n"
     ]
    }
   ],
   "source": [
    "if not RAGAS_AVAILABLE:\n",
    "    print(\"⚠️  RAGAS not available. Skipping evaluation.\")\n",
    "    print(\"   Install with: pip install ragas datasets\")\n",
    "else:\n",
    "    print_section_header(\"Running RAGAS Evaluation\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = Dataset.from_dict(ragas_data)\n",
    "    \n",
    "    print(\"\\nEvaluating with RAGAS metrics...\")\n",
    "    print(\"(This may take a few minutes)\\n\")\n",
    "    \n",
    "    # Initialize LLM and embeddings for RAGAS\n",
    "    # RAGAS 0.3+ requires explicit LLM and embeddings\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from ragas.dataset_schema import EvaluationResult\n",
    "    \n",
    "    ragas_llm = ChatOpenAI(model=DEFAULT_MODEL, temperature=0)\n",
    "    ragas_embeddings = OpenAIEmbeddings(model=OPENAI_EMBEDDING_MODEL)\n",
    "    \n",
    "    # Run evaluation with explicit LLM and embeddings\n",
    "    # Set return_executor=False explicitly to get EvaluationResult\n",
    "    result = evaluate(\n",
    "        dataset,\n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "        ],\n",
    "        llm=ragas_llm,\n",
    "        embeddings=ragas_embeddings,\n",
    "        return_executor=False,  # Explicitly return EvaluationResult, not Executor\n",
    "    )\n",
    "    \n",
    "    # Type assertion for Pylance - result is EvaluationResult when return_executor=False\n",
    "    assert isinstance(result, EvaluationResult), \"Expected EvaluationResult\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RAGAS EVALUATION RESULTS:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Convert result to DataFrame - this contains only the metric scores\n",
    "    scores_df = result.to_pandas()\n",
    "    \n",
    "    # Combine original data with evaluation scores\n",
    "    original_df = pd.DataFrame(ragas_data)\n",
    "    df = pd.concat([original_df, scores_df], axis=1)\n",
    "    \n",
    "    # Calculate and display overall scores\n",
    "    print(\"\\nOverall Scores:\")\n",
    "    metric_cols = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']\n",
    "    \n",
    "    for metric in metric_cols:\n",
    "        if metric in df.columns:\n",
    "            avg_score = df[metric].mean()\n",
    "            print(f\"  • {metric}: {avg_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"  • {metric}: Not available\")\n",
    "    \n",
    "    # Display per-question scores\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Per-Question Scores:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    available_metrics = [m for m in metric_cols if m in df.columns]\n",
    "    \n",
    "    if available_metrics:\n",
    "        # Display question and metrics\n",
    "        display_df = df[['question'] + available_metrics].copy()\n",
    "        # Truncate long questions for readability\n",
    "        display_df['question'] = display_df['question'].str[:60] + '...'\n",
    "        print(display_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"⚠️  No metric columns found in results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Results by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS BY QUESTION CATEGORY\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Average scores by category:\n",
      "\n",
      "\n",
      "SIMPLE:\n",
      "------------------------------------------------------------\n",
      "  • faithfulness: 1.0000\n",
      "  • answer_relevancy: 0.0000\n",
      "  • context_precision: 0.0000\n",
      "  • context_recall: 0.0000\n",
      "\n",
      "MULTI-STEP:\n",
      "------------------------------------------------------------\n",
      "  • faithfulness: 1.0000\n",
      "  • answer_relevancy: 0.0000\n",
      "  • context_precision: 1.0000\n",
      "  • context_recall: 0.0000\n",
      "\n",
      "MULTI-CONCEPT:\n",
      "------------------------------------------------------------\n",
      "  • faithfulness: 0.6000\n",
      "  • answer_relevancy: 1.0000\n",
      "  • context_precision: 0.0000\n",
      "  • context_recall: 0.0000\n",
      "\n",
      "CONCEPTUAL:\n",
      "------------------------------------------------------------\n",
      "  • faithfulness: 0.8182\n",
      "  • answer_relevancy: 0.7024\n",
      "  • context_precision: 0.4167\n",
      "  • context_recall: 0.3333\n",
      "\n",
      "COMPARISON:\n",
      "------------------------------------------------------------\n",
      "  • faithfulness: 1.0000\n",
      "  • answer_relevancy: 0.0000\n",
      "  • context_precision: 0.5000\n",
      "  • context_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if RAGAS_AVAILABLE:\n",
    "    print_section_header(\"Analysis by Question Category\")\n",
    "    \n",
    "    # Add categories to results\n",
    "    df['category'] = [item['category'] for item in evaluation_dataset]\n",
    "    \n",
    "    # Group by category\n",
    "    metrics = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"\\nAverage scores by category:\\n\")\n",
    "    for category in df['category'].unique():\n",
    "        cat_df = df[df['category'] == category]\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        print(\"-\" * 60)\n",
    "        for metric in metrics:\n",
    "            if metric in cat_df.columns:\n",
    "                avg_score = cat_df[metric].mean()\n",
    "                print(f\"  • {metric}: {avg_score:.4f}\")\n",
    "            else:\n",
    "                print(f\"  • {metric}: Not found in DataFrame\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Identify Weak Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "IDENTIFYING WEAK POINTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Questions needing improvement:\n",
      "\n",
      "\n",
      "FAITHFULNESS:\n",
      "--------------------------------------------------------------------------------\n",
      "Lowest score: 0.6000\n",
      "Question: What are the different types of memory in LangChain?\n",
      "Category: multi-concept\n",
      "Answer preview: The different types of memory in LangChain mentioned in the context are:\n",
      "\n",
      "1. **Short-term memory** - This supports multi-turn interactions.\n",
      "2. **Long-...\n",
      "\n",
      "ANSWER_RELEVANCY:\n",
      "--------------------------------------------------------------------------------\n",
      "Lowest score: 0.0000\n",
      "Question: What is LCEL in LangChain?\n",
      "Category: simple\n",
      "Answer preview: The context provided does not contain any information about \"LCEL\" in LangChain. Therefore, I cannot answer your question....\n",
      "\n",
      "CONTEXT_PRECISION:\n",
      "--------------------------------------------------------------------------------\n",
      "Lowest score: 0.0000\n",
      "Question: What is LCEL in LangChain?\n",
      "Category: simple\n",
      "Answer preview: The context provided does not contain any information about \"LCEL\" in LangChain. Therefore, I cannot answer your question....\n",
      "\n",
      "CONTEXT_RECALL:\n",
      "--------------------------------------------------------------------------------\n",
      "Lowest score: 0.0000\n",
      "Question: What is LCEL in LangChain?\n",
      "Category: simple\n",
      "Answer preview: The context provided does not contain any information about \"LCEL\" in LangChain. Therefore, I cannot answer your question....\n"
     ]
    }
   ],
   "source": [
    "if RAGAS_AVAILABLE:\n",
    "    print_section_header(\"Identifying Weak Points\")\n",
    "    \n",
    "    # Find questions with lowest scores\n",
    "    print(\"\\nQuestions needing improvement:\\n\")\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric in df.columns:\n",
    "            print(f\"\\n{metric.upper()}:\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # Get lowest scoring question\n",
    "            min_idx = df[metric].idxmin()\n",
    "            min_row = df.loc[min_idx]\n",
    "            \n",
    "            print(f\"Lowest score: {min_row[metric]:.4f}\")\n",
    "            print(f\"Question: {min_row['question']}\")\n",
    "            print(f\"Category: {min_row['category']}\")\n",
    "            print(f\"Answer preview: {min_row['answer'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VISUALIZING RESULTS\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Visualization complete\n"
     ]
    }
   ],
   "source": [
    "if RAGAS_AVAILABLE:\n",
    "    print_section_header(\"Visualizing Results\")\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Bar chart of metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    metric_names = []\n",
    "    metric_scores = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric in df.columns:\n",
    "            metric_names.append(metric.replace('_', ' ').title())\n",
    "            metric_scores.append(df[metric].mean())\n",
    "    \n",
    "    bars = ax.bar(metric_names, metric_scores, color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c'])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('RAGAS Evaluation Metrics - Simple RAG', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                '{:.3f}'.format(height),\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Architecture Comparison Framework\n",
    "\n",
    "Framework for comparing multiple RAG architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ARCHITECTURE COMPARISON FRAMEWORK\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Architecture Comparison (Sample):\n",
      "================================================================================\n",
      "                faithfulness  answer_relevancy  context_precision  context_recall  avg_latency  cost_per_query\n",
      "Simple RAG              0.85              0.82               0.78            0.75          1.2           0.002\n",
      "Contextual RAG          0.88              0.86               0.83            0.79          1.3           0.002\n",
      "Fusion RAG              0.87              0.85               0.84            0.82          3.5           0.006\n",
      "\n",
      "================================================================================\n",
      "RANKING BY METRIC:\n",
      "================================================================================\n",
      "\n",
      "FAITHFULNESS:\n",
      "  1. Contextual RAG: 0.880\n",
      "  2. Fusion RAG: 0.870\n",
      "  3. Simple RAG: 0.850\n",
      "\n",
      "ANSWER_RELEVANCY:\n",
      "  1. Contextual RAG: 0.860\n",
      "  2. Fusion RAG: 0.850\n",
      "  3. Simple RAG: 0.820\n",
      "\n",
      "CONTEXT_PRECISION:\n",
      "  1. Fusion RAG: 0.840\n",
      "  2. Contextual RAG: 0.830\n",
      "  3. Simple RAG: 0.780\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Architecture Comparison Framework\")\n",
    "\n",
    "# This would be used to compare all 12 architectures\n",
    "architecture_results = {\n",
    "    \"Simple RAG\": {\n",
    "        \"faithfulness\": 0.85,\n",
    "        \"answer_relevancy\": 0.82,\n",
    "        \"context_precision\": 0.78,\n",
    "        \"context_recall\": 0.75,\n",
    "        \"avg_latency\": 1.2,\n",
    "        \"cost_per_query\": 0.002,\n",
    "    },\n",
    "    \"Contextual RAG\": {\n",
    "        \"faithfulness\": 0.88,\n",
    "        \"answer_relevancy\": 0.86,\n",
    "        \"context_precision\": 0.83,\n",
    "        \"context_recall\": 0.79,\n",
    "        \"avg_latency\": 1.3,\n",
    "        \"cost_per_query\": 0.002,\n",
    "    },\n",
    "    \"Fusion RAG\": {\n",
    "        \"faithfulness\": 0.87,\n",
    "        \"answer_relevancy\": 0.85,\n",
    "        \"context_precision\": 0.84,\n",
    "        \"context_recall\": 0.82,\n",
    "        \"avg_latency\": 3.5,\n",
    "        \"cost_per_query\": 0.006,\n",
    "    },\n",
    "    # ... other architectures\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(architecture_results).T\n",
    "\n",
    "print(\"\\nArchitecture Comparison (Sample):\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RANKING BY METRIC:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for metric in ['faithfulness', 'answer_relevancy', 'context_precision']:\n",
    "    print(f\"\\n{metric.upper()}:\")\n",
    "    ranked = comparison_df.sort_values(metric, ascending=False)\n",
    "    for i, (arch, row) in enumerate(ranked.iterrows(), 1):\n",
    "        print(f\"  {i}. {arch}: {row[metric]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cost-Quality Trade-off Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COST-QUALITY TRADE-OFF ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Quality Score = Average of all metrics\n",
      "Efficiency = Quality / (Latency × Cost)\n",
      "\n",
      "================================================================================\n",
      "RANKINGS:\n",
      "================================================================================\n",
      "\n",
      "1. Best Quality:\n",
      "  1. Fusion RAG: 0.845\n",
      "  2. Contextual RAG: 0.840\n",
      "  3. Simple RAG: 0.800\n",
      "\n",
      "2. Fastest:\n",
      "  1. Simple RAG: 1.20s\n",
      "  2. Contextual RAG: 1.30s\n",
      "  3. Fusion RAG: 3.50s\n",
      "\n",
      "3. Most Cost-Effective:\n",
      "  1. Simple RAG: $0.0020\n",
      "  2. Contextual RAG: $0.0020\n",
      "  3. Fusion RAG: $0.0060\n",
      "\n",
      "4. Best Efficiency (Quality/Cost/Speed):\n",
      "  1. Simple RAG: 0.33\n",
      "  2. Contextual RAG: 0.32\n",
      "  3. Fusion RAG: 0.04\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Cost-Quality Trade-off Analysis\")\n",
    "\n",
    "print(\"\\nQuality Score = Average of all metrics\")\n",
    "print(\"Efficiency = Quality / (Latency × Cost)\\n\")\n",
    "\n",
    "# Calculate quality score\n",
    "comparison_df['quality'] = comparison_df[[\n",
    "    'faithfulness', 'answer_relevancy', 'context_precision', 'context_recall'\n",
    "]].mean(axis=1)\n",
    "\n",
    "# Calculate efficiency\n",
    "comparison_df['efficiency'] = (\n",
    "    comparison_df['quality'] / \n",
    "    (comparison_df['avg_latency'] * comparison_df['cost_per_query'] * 1000)\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RANKINGS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Best Quality:\")\n",
    "ranked_quality = comparison_df.sort_values('quality', ascending=False)\n",
    "for i, (arch, row) in enumerate(ranked_quality.iterrows(), 1):\n",
    "    print(f\"  {i}. {arch}: {row['quality']:.3f}\")\n",
    "\n",
    "print(\"\\n2. Fastest:\")\n",
    "ranked_speed = comparison_df.sort_values('avg_latency')\n",
    "for i, (arch, row) in enumerate(ranked_speed.iterrows(), 1):\n",
    "    print(f\"  {i}. {arch}: {row['avg_latency']:.2f}s\")\n",
    "\n",
    "print(\"\\n3. Most Cost-Effective:\")\n",
    "ranked_cost = comparison_df.sort_values('cost_per_query')\n",
    "for i, (arch, row) in enumerate(ranked_cost.iterrows(), 1):\n",
    "    print(f\"  {i}. {arch}: ${row['cost_per_query']:.4f}\")\n",
    "\n",
    "print(\"\\n4. Best Efficiency (Quality/Cost/Speed):\")\n",
    "ranked_efficiency = comparison_df.sort_values('efficiency', ascending=False)\n",
    "for i, (arch, row) in enumerate(ranked_efficiency.iterrows(), 1):\n",
    "    print(f\"  {i}. {arch}: {row['efficiency']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ARCHITECTURE RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "RECOMMENDATIONS BY USE CASE:\n",
      "================================================================================\n",
      "\n",
      "Production Quality:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: Fusion RAG or Contextual RAG\n",
      "  Reason: Best quality metrics with reasonable cost\n",
      "  Key metrics: High faithfulness, precision, recall\n",
      "\n",
      "Cost Sensitive:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: Simple RAG or Adaptive RAG\n",
      "  Reason: Low cost per query, good baseline quality\n",
      "  Key metrics: Balanced cost/quality ratio\n",
      "\n",
      "Low Latency:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: Simple RAG or Contextual RAG\n",
      "  Reason: Fastest response times\n",
      "  Key metrics: Sub-2s latency\n",
      "\n",
      "Complex Queries:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: Fusion RAG or Agentic RAG\n",
      "  Reason: Handle multi-faceted questions\n",
      "  Key metrics: High context recall, multi-hop reasoning\n",
      "\n",
      "Structured Data:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: SQL RAG\n",
      "  Reason: Direct database queries, precise results\n",
      "  Key metrics: 100% precision for data queries\n",
      "\n",
      "Relationship Queries:\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommended: GraphRAG\n",
      "  Reason: Entity relationships, multi-hop\n",
      "  Key metrics: Best for 'how are X and Y related'\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Architecture Recommendations\")\n",
    "\n",
    "def get_recommendation(use_case: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get architecture recommendation based on use case.\n",
    "    \"\"\"\n",
    "    recommendations = {\n",
    "        \"production_quality\": {\n",
    "            \"architecture\": \"Fusion RAG or Contextual RAG\",\n",
    "            \"reason\": \"Best quality metrics with reasonable cost\",\n",
    "            \"metrics\": \"High faithfulness, precision, recall\",\n",
    "        },\n",
    "        \"cost_sensitive\": {\n",
    "            \"architecture\": \"Simple RAG or Adaptive RAG\",\n",
    "            \"reason\": \"Low cost per query, good baseline quality\",\n",
    "            \"metrics\": \"Balanced cost/quality ratio\",\n",
    "        },\n",
    "        \"low_latency\": {\n",
    "            \"architecture\": \"Simple RAG or Contextual RAG\",\n",
    "            \"reason\": \"Fastest response times\",\n",
    "            \"metrics\": \"Sub-2s latency\",\n",
    "        },\n",
    "        \"complex_queries\": {\n",
    "            \"architecture\": \"Fusion RAG or Agentic RAG\",\n",
    "            \"reason\": \"Handle multi-faceted questions\",\n",
    "            \"metrics\": \"High context recall, multi-hop reasoning\",\n",
    "        },\n",
    "        \"structured_data\": {\n",
    "            \"architecture\": \"SQL RAG\",\n",
    "            \"reason\": \"Direct database queries, precise results\",\n",
    "            \"metrics\": \"100% precision for data queries\",\n",
    "        },\n",
    "        \"relationship_queries\": {\n",
    "            \"architecture\": \"GraphRAG\",\n",
    "            \"reason\": \"Entity relationships, multi-hop\",\n",
    "            \"metrics\": \"Best for 'how are X and Y related'\",\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    return recommendations.get(use_case, {})\n",
    "\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS BY USE CASE:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "use_cases = [\n",
    "    \"production_quality\",\n",
    "    \"cost_sensitive\",\n",
    "    \"low_latency\",\n",
    "    \"complex_queries\",\n",
    "    \"structured_data\",\n",
    "    \"relationship_queries\",\n",
    "]\n",
    "\n",
    "for use_case in use_cases:\n",
    "    rec = get_recommendation(use_case)\n",
    "    print(f\"\\n{use_case.replace('_', ' ').title()}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"  Recommended: {rec.get('architecture', 'N/A')}\")\n",
    "    print(f\"  Reason: {rec.get('reason', 'N/A')}\")\n",
    "    print(f\"  Key metrics: {rec.get('metrics', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Takeaways\n",
    "\n",
    "### RAGAS Metrics Explained\n",
    "\n",
    "1. **Faithfulness** (0-1)\n",
    "   - Measures: Hallucination / groundedness\n",
    "   - How: Checks if answer is supported by context\n",
    "   - Good: > 0.85\n",
    "   - Improve: Better prompts, more context, fact-checking\n",
    "\n",
    "2. **Answer Relevancy** (0-1)\n",
    "   - Measures: Answer addresses question\n",
    "   - How: Semantic similarity to query\n",
    "   - Good: > 0.80\n",
    "   - Improve: Better prompts, query understanding\n",
    "\n",
    "3. **Context Precision** (0-1)\n",
    "   - Measures: Retrieved docs are relevant\n",
    "   - How: Checks if context matches ground truth\n",
    "   - Good: > 0.75\n",
    "   - Improve: Better retrieval, reranking\n",
    "\n",
    "4. **Context Recall** (0-1)\n",
    "   - Measures: Retrieved all relevant info\n",
    "   - How: Coverage of ground truth\n",
    "   - Good: > 0.75\n",
    "   - Improve: More retrievals, better chunking\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**Dataset Creation:**\n",
    "- ✅ Diverse question types\n",
    "- ✅ Cover edge cases\n",
    "- ✅ Include failure modes\n",
    "- ✅ Real user queries\n",
    "- ✅ 20-50 test cases minimum\n",
    "\n",
    "**Ground Truth:**\n",
    "- ✅ Expert-written answers\n",
    "- ✅ Factually correct\n",
    "- ✅ Concise and clear\n",
    "- ✅ Covers key points\n",
    "\n",
    "**Continuous Evaluation:**\n",
    "- ✅ Run on every major change\n",
    "- ✅ Track metrics over time\n",
    "- ✅ A/B test architectures\n",
    "- ✅ Monitor production queries\n",
    "\n",
    "### Interpreting Results\n",
    "\n",
    "**High Faithfulness, Low Recall:**\n",
    "- Answer is grounded but incomplete\n",
    "- → Increase k (retrieve more docs)\n",
    "\n",
    "**Low Precision, High Recall:**\n",
    "- Retrieved too much noise\n",
    "- → Add reranking, better chunking\n",
    "\n",
    "**Low Relevancy:**\n",
    "- Answer doesn't address question\n",
    "- → Improve prompt, add examples\n",
    "\n",
    "**All Low Scores:**\n",
    "- Fundamental issues\n",
    "- → Check data quality, embeddings, prompts\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "**Pre-deployment:**\n",
    "1. RAGAS scores > 0.75 on all metrics\n",
    "2. Latency < 3s for 95th percentile\n",
    "3. Cost per query acceptable\n",
    "4. Manual review of edge cases\n",
    "\n",
    "**Post-deployment:**\n",
    "1. Log all queries and responses\n",
    "2. Sample for human evaluation\n",
    "3. Track user feedback\n",
    "4. Monitor RAGAS on production data\n",
    "5. A/B test improvements\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Expand dataset**: Add more test cases\n",
    "2. **Evaluate all architectures**: Run comparison\n",
    "3. **Optimize weak points**: Focus on low-scoring areas\n",
    "4. **Set up CI/CD**: Automate evaluation\n",
    "5. **Production monitoring**: Track real-world performance\n",
    "\n",
    "---\n",
    "\n",
    "**Importance:** ⭐⭐⭐⭐⭐ (Critical - evaluation is essential for production)\n",
    "\n",
    "**Recommendation:** Run RAGAS evaluation on every architecture before production deployment!\n",
    "\n",
    "Project complete! You now have 12 RAG architectures + comprehensive evaluation framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
