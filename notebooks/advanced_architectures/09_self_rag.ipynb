{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Self-RAG (Self-Reflective RAG)\n",
    "\n",
    "**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "**Use Cases:** Exploratory research, quality-critical applications, self-correcting systems\n",
    "\n",
    "**Key Features:**\n",
    "- LLM decides autonomously when to retrieve\n",
    "- Self-critique mechanism\n",
    "- Iterative refinement\n",
    "- Citation validation\n",
    "\n",
    "**Flow:**\n",
    "```\n",
    "Query ‚Üí Need Retrieval? ‚Üí \n",
    "  Yes: Retrieve + Generate ‚Üí Self-Critique ‚Üí Retry if poor\n",
    "  No: Direct Generate ‚Üí Self-Critique\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianlucamazza/Workspace/notebooks/llm_rag/venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SETUP: SELF-RAG\n",
      "================================================================================\n",
      "\n",
      "‚úì Loaded vector store from /Users/gianlucamazza/Workspace/notebooks/llm_rag/notebooks/advanced_architectures/../../data/vector_stores/openai_embeddings\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from shared.config import OPENAI_VECTOR_STORE_PATH, DEFAULT_MODEL\n",
    "from shared.utils import load_vector_store, print_section_header, format_docs\n",
    "from shared.prompts import (\n",
    "    RETRIEVAL_NEED_PROMPT, SELF_CRITIQUE_PROMPT, \n",
    "    CITATION_CHECK_PROMPT, RAG_PROMPT_TEMPLATE\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "print_section_header(\"Setup: Self-RAG\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = load_vector_store(OPENAI_VECTOR_STORE_PATH, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "llm = ChatOpenAI(model=DEFAULT_MODEL, temperature=0)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Self-RAG Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SELF-RAG COMPONENTS\n",
      "================================================================================\n",
      "\n",
      "‚úì Self-RAG components initialized:\n",
      "  - Retrieval need decider\n",
      "  - Response critic\n",
      "  - Citation checker\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Self-RAG Components\")\n",
    "\n",
    "# Retrieval need decider\n",
    "retrieval_decider = RETRIEVAL_NEED_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "# Response critic\n",
    "response_critic = SELF_CRITIQUE_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "# Citation checker\n",
    "citation_checker = CITATION_CHECK_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "print(\"‚úì Self-RAG components initialized:\")\n",
    "print(\"  - Retrieval need decider\")\n",
    "print(\"  - Response critic\")\n",
    "print(\"  - Citation checker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING SELF-RAG COMPONENTS\n",
      "================================================================================\n",
      "\n",
      "Retrieval Need Decisions:\n",
      "\n",
      "NO  | What is 2+2?\n",
      "YES | What is RAG in LangChain?\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Testing Self-RAG Components\")\n",
    "\n",
    "# Test retrieval decision\n",
    "queries = [\n",
    "    \"What is 2+2?\",  # NO retrieval\n",
    "    \"What is RAG in LangChain?\",  # YES retrieval\n",
    "]\n",
    "\n",
    "print(\"Retrieval Need Decisions:\\n\")\n",
    "for q in queries:\n",
    "    decision = retrieval_decider.invoke({\"query\": q}).strip()\n",
    "    print(f\"{decision:3} | {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Self-RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SELF-RAG PIPELINE\n",
      "================================================================================\n",
      "\n",
      "‚úì Self-RAG pipeline ready\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Self-RAG Pipeline\")\n",
    "\n",
    "def self_rag_pipeline(query: str, max_iterations: int = 2):\n",
    "    \"\"\"Self-RAG with iterative refinement.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\n--- Iteration {iteration} ---\")\n",
    "        \n",
    "        # Decide if retrieval needed\n",
    "        need_retrieval = retrieval_decider.invoke({\"query\": query})\n",
    "        print(f\"Retrieval needed: {need_retrieval.strip()}\")\n",
    "        \n",
    "        # Retrieve or use general knowledge\n",
    "        if \"YES\" in need_retrieval.upper():\n",
    "            docs = retriever.invoke(query)\n",
    "            context = format_docs(docs)\n",
    "            print(f\"Retrieved {len(docs)} documents\")\n",
    "        else:\n",
    "            context = \"Using general knowledge.\"\n",
    "            print(\"Using general knowledge only\")\n",
    "        \n",
    "        # Generate response\n",
    "        gen_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"Context: {context}\"),\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "        response = (gen_prompt | llm | StrOutputParser()).invoke({\"query\": query})\n",
    "        print(f\"\\nGenerated ({len(response)} chars)\")\n",
    "        \n",
    "        # Self-critique\n",
    "        critique = response_critic.invoke({\n",
    "            \"query\": query,\n",
    "            \"context\": context[:1000],\n",
    "            \"response\": response\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüîç Critique:\\n{critique}\")\n",
    "        \n",
    "        # Check if retry needed\n",
    "        if \"SHOULD_RETRY: yes\" not in critique.lower():\n",
    "            print(\"\\n‚úì Response approved!\")\n",
    "            return response, iteration, critique\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  Retrying with refinement...\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Max iterations reached\")\n",
    "    return response, iteration, critique\n",
    "\n",
    "print(\"‚úì Self-RAG pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Self-RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SELF-RAG TEST\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: What is the difference between similarity and MMR retrieval?\n",
      "================================================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Retrieval needed: YES\n",
      "Retrieved 4 documents\n",
      "\n",
      "Generated (1994 chars)\n",
      "\n",
      "üîç Critique:\n",
      "SCORE: 5  \n",
      "ISSUES: None  \n",
      "SHOULD_RETRY: no  \n",
      "\n",
      "The response accurately explains the differences between similarity retrieval and MMR retrieval, providing clear definitions, mechanisms, goals, and use cases for each approach. It is complete and relevant to the question asked.\n",
      "\n",
      "‚úì Response approved!\n",
      "\n",
      "\n",
      "Final Response (1 iteration):\n",
      "Similarity retrieval and Maximum Marginal Relevance (MMR) retrieval are two different approaches used in information retrieval and document ranking. Here‚Äôs a breakdown of their differences:\n",
      "\n",
      "### Similarity Retrieval\n",
      "- **Definition**: Similarity retrieval focuses on finding documents that are most si\n"
     ]
    }
   ],
   "source": [
    "print_section_header(\"Self-RAG Test\")\n",
    "\n",
    "# Test 1: Query needing retrieval\n",
    "query1 = \"What is the difference between similarity and MMR retrieval?\"\n",
    "response1, iters1, _ = self_rag_pipeline(query1)\n",
    "\n",
    "print(f\"\\n\\nFinal Response ({iters1} iteration{'s' if iters1 > 1 else ''}):\")\n",
    "print(response1[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: What is 5 + 7?\n",
      "================================================================================\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Retrieval needed: NO\n",
      "Using general knowledge only\n",
      "\n",
      "Generated (16 chars)\n",
      "\n",
      "üîç Critique:\n",
      "SCORE: 5  \n",
      "ISSUES: None  \n",
      "SHOULD_RETRY: no\n",
      "\n",
      "‚úì Response approved!\n",
      "\n",
      "\n",
      "Final Response (1 iteration):\n",
      "5 + 7 equals 12.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Simple query (no retrieval)\n",
    "query2 = \"What is 5 + 7?\"\n",
    "response2, iters2, _ = self_rag_pipeline(query2)\n",
    "\n",
    "print(f\"\\n\\nFinal Response ({iters2} iteration{'s' if iters2 > 1 else ''}):\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Advantages:**\n",
    "‚úÖ Autonomous decision-making  \n",
    "‚úÖ Self-correction capability  \n",
    "‚úÖ Only retrieves when needed (efficient)  \n",
    "‚úÖ Quality assurance built-in  \n",
    "\n",
    "**Limitations:**\n",
    "- Very slow (multiple LLM calls)\n",
    "- Expensive (iterations + critique)\n",
    "- Complex to tune\n",
    "- May over-correct\n",
    "\n",
    "**When to Use:**\n",
    "- Quality is paramount\n",
    "- Research applications\n",
    "- Self-correcting systems\n",
    "- Budget allows higher cost\n",
    "\n",
    "**Production Tips:**\n",
    "- Limit max iterations\n",
    "- Cache critique results\n",
    "- Monitor iteration distribution\n",
    "- Set quality thresholds\n",
    "\n",
    "**Next:** [10_agentic_rag.ipynb](10_agentic_rag.ipynb) - Autonomous agents with tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
